{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BillGates.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-35gnQG8yoS"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtgVmnvnaXEG"
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.efficientnet import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import adam_v2\n",
        "\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as tfk\n",
        "import tensorflow.keras.layers as tfkl\n",
        "import random\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CsuuFtBRg5H"
      },
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 4\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voCaRwS49Mol"
      },
      "source": [
        "# Set the path for training\n",
        "train_dir = 'splitDataset/train'\n",
        "\n",
        "# Set the path for validation\n",
        "val_dir = 'splitDataset/validation'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIUwfyrIS9hQ"
      },
      "source": [
        "# We create instances of ImageDataGenerator for preprocessing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# We are augmenting the data and preprocessed them with the Efficientnet preprocessing function \n",
        "aug_train_data_gen = ImageDataGenerator( horizontal_flip=True,\n",
        "                                  rotation_range=90,\n",
        "                                  vertical_flip=True,\n",
        "                                  height_shift_range=0.3,\n",
        "                                  width_shift_range=0.3,\n",
        "                                  brightness_range=[0.7,1.3],\n",
        "                                  preprocessing_function=preprocess_input)\n",
        "\n",
        "noaug_val_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Generates the dataset for training \n",
        "aug_train_gen = aug_train_data_gen.flow_from_directory(directory=train_dir,\n",
        "                                                           target_size=(256,256),\n",
        "                                                           color_mode='rgb',\n",
        "                                                           classes=None,\n",
        "                                                           class_mode='categorical',\n",
        "                                                           batch_size=16,\n",
        "                                                           shuffle=True,\n",
        "                                                           seed=seed)\n",
        "# Generates the dataset for validation \n",
        "noaug_val_gen = noaug_val_data_gen.flow_from_directory(directory=val_dir,\n",
        "                                                           target_size=(256,256),\n",
        "                                                           color_mode='rgb',\n",
        "                                                           classes=None,\n",
        "                                                           class_mode='categorical',\n",
        "                                                           batch_size=16,\n",
        "                                                           shuffle=True,\n",
        "                                                           seed=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZNmioa6XU4A"
      },
      "source": [
        "# Set the number of epochs for training\n",
        "epochs = 200\n",
        "# Set input shape\n",
        "input_shape = (256, 256, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WprzYvsacoL"
      },
      "source": [
        "\n",
        "# Instantiates the Efficient architecture\n",
        "base_model = tfk.applications.EfficientNetB7(weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(input_shape, include_top=False)\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "\n",
        "inputs = tfk.Input(shape=input_shape)\n",
        "\n",
        "# Instantiates the GAP and Batch Normalization layers\n",
        "x = base_model(inputs, training=False)\n",
        "x = tfkl.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
        "x = tfkl.BatchNormalization()(x)\n",
        "x = tfkl.Dropout(0.3, name=\"top_dropout\")(x)\n",
        "\n",
        "output_layer = tfkl.Dense(units=14, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='Output')(x)\n",
        "\n",
        "# Istantiate the Model class\n",
        "model = tfk.Model(inputs, output_layer)\n",
        "   \n",
        "# Compile the model\n",
        "model.compile(optimizer=tfk.optimizers.Adam(),\n",
        "              loss=tfk.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy',tfk.metrics.AUC(),tfk.metrics.Precision(),tfk.metrics.Recall()])\n",
        "# Show the structure of the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qbixQiprQl_"
      },
      "source": [
        "# Utility function to create folders and callbacks for training\n",
        "from datetime import datetime\n",
        "\n",
        "def create_folders_and_callbacks(model_name):\n",
        "\n",
        "  exps_dir = os.path.join('data_callbacks_experiments')\n",
        "  if not os.path.exists(exps_dir):\n",
        "      os.makedirs(exps_dir)\n",
        "\n",
        "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "  if not os.path.exists(exp_dir):\n",
        "      os.makedirs(exp_dir)\n",
        "      \n",
        "  callbacks = []\n",
        "\n",
        "  # Model checkpoint\n",
        "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "  if not os.path.exists(ckpt_dir):\n",
        "      os.makedirs(ckpt_dir)\n",
        "\n",
        "  # Callback to save the model\n",
        "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
        "                                                     save_weights_only=False, # True to save only weights\n",
        "                                                     save_best_only=False) # True to save only the best epoch \n",
        "  callbacks.append(ckpt_callback)\n",
        "\n",
        "  # Early Stopping\n",
        "  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "  callbacks.append(es_callback)\n",
        "\n",
        "  # Method to reduce learning rate when a metric has stopped improving\n",
        "  reduce_lr = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, min_lr=1e-5)\n",
        "  callbacks.append(reduce_lr)\n",
        "\n",
        "  return callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWoc-JLiG1XR"
      },
      "source": [
        "# We will first train the Dense layers, so we are going to freeze the convolutional part\n",
        "for i, layer in enumerate(model.get_layer('efficientnetb7').layers):\n",
        "  layer.trainable=False\n",
        "for i, layer in enumerate(model.get_layer('efficientnetb7').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "# Show the structure of the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sljBZmiedDE9"
      },
      "source": [
        "# Create folders and callbacks and fit\n",
        "aug_callbacks = create_folders_and_callbacks(model_name='BillGates_transfL')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = aug_train_gen,\n",
        "    epochs = epochs,\n",
        "    validation_data = noaug_val_gen,\n",
        "    callbacks = aug_callbacks,\n",
        "    initial_epoch=27).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnBKxbpQva_C"
      },
      "source": [
        "model.save(\"experiments/BillGates_transfL\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AtfWvpjajRA"
      },
      "source": [
        "metrics = model.evaluate(noaug_val_gen,return_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5_nEs9ndWxM"
      },
      "source": [
        "model.get_layer('efficientnetb7').trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_orqwtwNZG1W"
      },
      "source": [
        "# we decide to freeze the first 751 layers and unfreeze the rest\n",
        "for i, layer in enumerate(model.get_layer('efficientnetb7').layers[:751]):\n",
        "  layer.trainable=False\n",
        "for i, layer in enumerate(model.get_layer('efficientnetb7').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "# Show the structure of the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4nzIunEdb_D"
      },
      "source": [
        "# Create folders and callbacks\n",
        "aug_callbacks = create_folders_and_callbacks(model_name='BillGates_fineTuned')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = aug_train_gen,\n",
        "    epochs = epochs,\n",
        "    validation_data = noaug_val_gen,\n",
        "    callbacks = aug_callbacks).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c462VPMwd4E0"
      },
      "source": [
        "# Save the fine tuned model\n",
        "model.save(\"experiments/BillGates_fineTuned\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}