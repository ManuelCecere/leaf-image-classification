{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "MarkZuckerberg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-11-24T16:38:15.106373Z",
          "iopub.execute_input": "2021-11-24T16:38:15.106644Z",
          "iopub.status.idle": "2021-11-24T16:38:21.769314Z",
          "shell.execute_reply.started": "2021-11-24T16:38:15.106615Z",
          "shell.execute_reply": "2021-11-24T16:38:21.767981Z"
        },
        "trusted": true,
        "id": "BCzEwUIfDcS2"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import keras_tuner as kt\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-24T16:38:22.611116Z",
          "iopub.execute_input": "2021-11-24T16:38:22.611419Z",
          "iopub.status.idle": "2021-11-24T16:38:22.618849Z",
          "shell.execute_reply.started": "2021-11-24T16:38:22.611389Z",
          "shell.execute_reply": "2021-11-24T16:38:22.617496Z"
        },
        "trusted": true,
        "id": "fT40YNcRDcS6"
      },
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T10:03:36.415226Z",
          "iopub.execute_input": "2021-11-21T10:03:36.416433Z",
          "iopub.status.idle": "2021-11-21T10:03:36.428282Z",
          "shell.execute_reply.started": "2021-11-21T10:03:36.416354Z",
          "shell.execute_reply": "2021-11-21T10:03:36.427508Z"
        },
        "trusted": true,
        "id": "pYqpIl-eDcS7"
      },
      "source": [
        "# Folder in which we save the dataset\n",
        "dataset_dir = 'splitDataset'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T10:03:36.429333Z",
          "iopub.execute_input": "2021-11-21T10:03:36.430139Z",
          "iopub.status.idle": "2021-11-21T10:03:54.846961Z",
          "shell.execute_reply.started": "2021-11-21T10:03:36.430101Z",
          "shell.execute_reply": "2021-11-21T10:03:54.846215Z"
        },
        "trusted": true,
        "id": "40AAbQpIDcS8"
      },
      "source": [
        "# We create instances of ImageDataGenerator for preprocessing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Generate batches of tensor image data with data augmentation\n",
        "aug_train_data_gen = ImageDataGenerator(rescale=1/255.,\n",
        "                                  horizontal_flip=True,\n",
        "                                  rotation_range=90,\n",
        "                                  vertical_flip=True,\n",
        "                                  height_shift_range=0.3,\n",
        "                                  width_shift_range=0.3,\n",
        "                                  brightness_range=[0.7,1.3])\n",
        "\n",
        "# Normalize data in order to have values between 0 and 1\n",
        "noaug_val_data_gen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "# Generates the dataset for training \n",
        "aug_train_gen = aug_train_data_gen.flow_from_directory(directory=dataset_dir + '/train',\n",
        "                                                           target_size=(256,256),\n",
        "                                                           color_mode='rgb',\n",
        "                                                           classes=None,\n",
        "                                                           class_mode='categorical',\n",
        "                                                           batch_size=16,\n",
        "                                                           shuffle=True,\n",
        "                                                           seed=seed\n",
        "                                                           )\n",
        "# Generates the dataset for validation \n",
        "noaug_val_gen = noaug_val_data_gen.flow_from_directory(directory=dataset_dir+'/validation',\n",
        "                                                           target_size=(256,256),\n",
        "                                                           color_mode='rgb',\n",
        "                                                           classes=None,\n",
        "                                                           class_mode='categorical',\n",
        "                                                           batch_size=16,\n",
        "                                                           shuffle=True,\n",
        "                                                           seed=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T10:03:54.849097Z",
          "iopub.execute_input": "2021-11-21T10:03:54.85012Z",
          "iopub.status.idle": "2021-11-21T10:03:54.854053Z",
          "shell.execute_reply.started": "2021-11-21T10:03:54.850079Z",
          "shell.execute_reply": "2021-11-21T10:03:54.853404Z"
        },
        "trusted": true,
        "id": "SuZkvMYcDcS8"
      },
      "source": [
        "# Set input shape\n",
        "input_shape = (256, 256, 3)\n",
        "# Set the number of epochs for training\n",
        "epochs = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T10:03:54.855612Z",
          "iopub.execute_input": "2021-11-21T10:03:54.856051Z",
          "iopub.status.idle": "2021-11-21T10:03:54.877217Z",
          "shell.execute_reply.started": "2021-11-21T10:03:54.856015Z",
          "shell.execute_reply": "2021-11-21T10:03:54.876502Z"
        },
        "trusted": true,
        "id": "Za8hVHNzDcS9"
      },
      "source": [
        "# (Conv + ReLU + Batch Normalization + MaxPool) x 6 + FC x 3\n",
        "def build_model(input_shape):\n",
        "\n",
        "    # Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    batch1 = tfkl.BatchNormalization()(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(batch1)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    batch2 = tfkl.BatchNormalization()(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(batch2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    batch3 = tfkl.BatchNormalization()(conv3)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(batch3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    batch4 = tfkl.BatchNormalization()(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(batch4)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    batch5 = tfkl.BatchNormalization()(conv5)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(batch5)\n",
        "    \n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    batch6 = tfkl.BatchNormalization()(conv6)\n",
        "    pool6 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(batch6)\n",
        "    \n",
        "    # Build the fully connected part\n",
        "    flattening_layer = tfkl.Flatten(name='Flatten')(pool6)\n",
        "    flattening_layer = tfkl.Dropout(0.3, seed=seed)(flattening_layer)\n",
        "    classifier_layer = tfkl.Dense(units=512, name='Classifier', kernel_initializer=tfk.initializers.GlorotUniform(seed), activation='relu')(flattening_layer)\n",
        "    classifier_layer = tfkl.Dropout(0.4, seed=seed)(classifier_layer)\n",
        "    classifier_layer1 = tfkl.Dense(units=512, name='Classifier1', kernel_initializer=tfk.initializers.GlorotUniform(seed), activation='relu')(classifier_layer)\n",
        "    classifier_layer1 = tfkl.Dropout(0.2, seed=seed)(classifier_layer1)\n",
        "    classifier_layer2 = tfkl.Dense(units=256, name='Classifier2', kernel_initializer=tfk.initializers.GlorotUniform(seed), activation='relu')(classifier_layer1)\n",
        "    classifier_layer2 = tfkl.Dropout(0.2, seed=seed)(classifier_layer2)\n",
        "    output_layer = tfkl.Dense(units=14, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='Output')(classifier_layer2)\n",
        "\n",
        "    # Istantiate the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy',tfk.metrics.AUC(),tfk.metrics.Precision(),tfk.metrics.Recall()])\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T10:03:54.87854Z",
          "iopub.execute_input": "2021-11-21T10:03:54.878961Z",
          "iopub.status.idle": "2021-11-21T10:03:54.889031Z",
          "shell.execute_reply.started": "2021-11-21T10:03:54.878926Z",
          "shell.execute_reply": "2021-11-21T10:03:54.888356Z"
        },
        "trusted": true,
        "id": "Q1UE-p5mDcS-"
      },
      "source": [
        "# Utility function to create folders and callbacks for training\n",
        "from datetime import datetime\n",
        "\n",
        "def create_folders_and_callbacks(model_name):\n",
        "\n",
        "  exps_dir = os.path.join('data_callbacks_experiments')\n",
        "  if not os.path.exists(exps_dir):\n",
        "      os.makedirs(exps_dir)\n",
        "\n",
        "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "  if not os.path.exists(exp_dir):\n",
        "      os.makedirs(exp_dir)\n",
        "      \n",
        "  callbacks = []\n",
        "\n",
        "  # Creation of model checkpoint\n",
        "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "  if not os.path.exists(ckpt_dir):\n",
        "      os.makedirs(ckpt_dir)\n",
        "\n",
        "  # Callback to save the model\n",
        "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
        "                                                     save_weights_only=False, # True to save only weights\n",
        "                                                     save_best_only=False) # True to save only the best epoch \n",
        "  callbacks.append(ckpt_callback)\n",
        "\n",
        "  # Early Stopping\n",
        "  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "  callbacks.append(es_callback)\n",
        "  # Method to reduce learning rate when the monitored metric has stopped improving\n",
        "  reduce_rl_callback=tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=4, factor=0.4, min_lr=0.00001,verbose=1),\n",
        "  callbacks.append(reduce_rl_callback)  \n",
        "  \n",
        "  return callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T10:03:54.89023Z",
          "iopub.execute_input": "2021-11-21T10:03:54.890936Z",
          "iopub.status.idle": "2021-11-21T10:03:57.286742Z",
          "shell.execute_reply.started": "2021-11-21T10:03:54.890902Z",
          "shell.execute_reply": "2021-11-21T10:03:57.286075Z"
        },
        "trusted": true,
        "id": "tLAcRtTPDcTA"
      },
      "source": [
        "# Instantiate the model\n",
        "model = build_model(input_shape)\n",
        "# Show the structure of the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T10:03:57.289471Z",
          "iopub.execute_input": "2021-11-21T10:03:57.289673Z",
          "iopub.status.idle": "2021-11-21T14:32:09.696922Z",
          "shell.execute_reply.started": "2021-11-21T10:03:57.289648Z",
          "shell.execute_reply": "2021-11-21T14:32:09.696194Z"
        },
        "trusted": true,
        "id": "LLRcIYkWDcTB"
      },
      "source": [
        "# Create folders and callbacks\n",
        "aug_callbacks = create_folders_and_callbacks(model_name='MarkZuckerberg')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x = aug_train_gen,epochs = epochs,validation_data = noaug_val_gen,callbacks = aug_callbacks).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T14:39:13.391713Z",
          "iopub.execute_input": "2021-11-21T14:39:13.392324Z",
          "iopub.status.idle": "2021-11-21T14:39:16.01647Z",
          "shell.execute_reply.started": "2021-11-21T14:39:13.392285Z",
          "shell.execute_reply": "2021-11-21T14:39:16.015527Z"
        },
        "trusted": true,
        "id": "3TPLXvEJDcTB"
      },
      "source": [
        "# Save the model\n",
        "model.save(\"experiments/MarkZuckerberg\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}